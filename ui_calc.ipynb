{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the profiles in UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "df = duckdb.sql(\"select * from read_parquet('person_profiles.parquet/*.parquet') where PersonID = 53380\").fetchdf()\n",
    "import json\n",
    "deets = json.loads(df['Details'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import udf, col, size, collect_set, collect_list\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from collections import Counter\n",
    "from pyspark.sql.functions import col, collect_set, struct,count\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType\n",
    "from datetime import date\n",
    "import statistics\n",
    "import json\n",
    "import calendar\n",
    "\n",
    "import polars as pl\n",
    "spark = SparkSession.builder.appName('customer360.ai').getOrCreate()\n",
    "\n",
    "\n",
    "df = spark.read.parquet(\"cdp_profiles.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_age(born_str):\n",
    "    born = date.fromisoformat(born_str)\n",
    "    today = date.today()\n",
    "    return today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n",
    "@udf \n",
    "def mode_udf(column_arr):\n",
    "    return statistics.mode(column_arr)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tried something different\n",
    "\n",
    "Timelines and anything to do with dates have to be properly sorted.\n",
    "> currently has some bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'first_name': 'xxxx', 'last_name': 'xxxx', 'email': 'tXXX@XXXX.com', 'mobile': 'Unknown', 'booker_type': 'Agent', 'city': 'Unknown', 'total_passengers': 1, 'unique': 1, 'first_date': '2022-10-06 12:37:57.18', 'last_date': '2022-10-06 12:37:57.18', 'booking_freq': {'jan': 0, 'feb': 0, 'mar': 0, 'apr': 0, 'may': 0, 'jun': 0, 'jul': 0, 'aug': 0, 'sep': 0, 'oct': 1, 'nov': 0, 'dec': 0}, 'seat_counts': {'21D_2F_9E_31E': 1}, 'meals_count': {'None': 1}, 'destination_count': {'BCD_MNL_MNL_SIN': 1}, 'channel_count': {'API': 1}, 'employee_count': {'No': 1}, 'baggage_count': {'Checked Baggage Allowance - 20 Kilos': 1}, 'gender_count': {'2': 1}, 'employee_related_count': {'No': 1}, 'insurance_count': {'None': 1}, 'origin_count': {'SIN': 1}, 'travelby_count': {'Solo': 1}, 'isregistered_count': {'No': 1}, 'revenue': 13.596599679999999, 'timeline': [{'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"SIN\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"BCD_MNL_MNL_SI…\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"Checked Baggag…\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2022-10-06 12:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"SGD13.59659967…\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"SIN\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"BCD_MNL_MNL_SI…\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"Checked Baggag…\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2022-10-06 12:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"SGD13.59659967…\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"SIN\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"BCD_MNL_MNL_SI…\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"Checked Baggag…\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2022-10-06 12:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"SGD13.59659967…\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"SIN\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"BCD_MNL_MNL_SI…\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"Checked Baggag…\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2022-10-06 12:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"SGD13.59659967…\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"SIN\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"BCD_MNL_MNL_SI…\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"Checked Baggag…\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2022-10-06 12:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"SGD13.59659967…\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"SIN\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"BCD_MNL_MNL_SI…\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"Checked Baggag…\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2022-10-06 12:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"SGD13.59659967…\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"SIN\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"BCD_MNL_MNL_SI…\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"Checked Baggag…\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2022-10-06 12:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"SGD13.59659967…\n",
      "]}]}\n",
      "{'first_name': 'xxxx', 'last_name': 'xxxx', 'email': 'Unknown', 'mobile': 'Unknown', 'booker_type': 'Agent', 'city': 'Unknown', 'total_passengers': 56, 'unique': 23, 'first_date': '2015-01-28 06:09:05.067', 'last_date': '2023-03-09 06:35:18.027', 'booking_freq': {'jan': 6, 'feb': 2, 'mar': 7, 'apr': 0, 'may': 3, 'jun': 2, 'jul': 6, 'aug': 3, 'sep': 6, 'oct': 7, 'nov': 11, 'dec': 3}, 'seat_counts': {'Unknown': 45, '42E_43C': 1, '48D': 1, '35B': 1, '34D': 1, '24A': 1, '45A': 1, '16C': 1, '26F': 1, '14D': 1, '1D_1D': 1, '11B_25F': 1}, 'meals_count': {'None': 56}, 'destination_count': {'Unknown': 45, 'DVO_MNL': 1, 'MNL': 6, 'BXU': 1, 'PPS': 1, 'DVO_DVO': 1, 'MNL_CEB': 1}, 'channel_count': {'GDS': 56}, 'employee_count': {'No': 56}, 'baggage_count': {'None': 48, 'Checked Baggage Allowance - 15 Kilos': 1, 'Checked Baggage Allowance - 40 Kilos': 3, 'Checked Baggage Allowance - 20 Kilos': 3, 'Checked Baggage Allowance - 32 Kilos': 1}, 'gender_count': {'1': 43, '2': 13}, 'employee_related_count': {'No': 56}, 'insurance_count': {'None': 56}, 'origin_count': {'Unknown': 45, 'MNL': 2, 'ICN': 5, 'CEB': 2, 'DVO': 1, 'ILO': 1}, 'travelby_count': {'Group': 31, 'Solo': 25}, 'isregistered_count': {'Yes': 34, 'No': 22}, 'revenue': 63267729.39122599, 'timeline': [{'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"GDS\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2023-03-09 06:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.0\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"GDS\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2023-03-09 06:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.0\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"GDS\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2023-03-09 06:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.0\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"GDS\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2023-03-09 06:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.0\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"GDS\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2023-03-09 06:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.0\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"GDS\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2023-03-09 06:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.0\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"GDS\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2023-03-09 06:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.0\"\n",
      "]}]}\n",
      "23/04/16 21:05:02 ERROR Executor: Exception in task 9.0 in stage 46.0 (TID 184)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_6942/4051122333.py\", line 168, in sum_ages\n",
      "  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/__init__.py\", line 231, in dumps\n",
      "    return _default_encoder.encode(obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 200, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 258, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type Series is not JSON serializable\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:561)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:94)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:75)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:514)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:385)\n",
      "\tat org.apache.spark.sql.execution.datasources.WriteFilesExec.$anonfun$doExecuteWrite$1(WriteFiles.scala:100)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:888)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:888)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "23/04/16 21:05:02 ERROR Executor: Exception in task 2.0 in stage 46.0 (TID 177)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_6942/4051122333.py\", line 168, in sum_ages\n",
      "  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/__init__.py\", line 231, in dumps\n",
      "    return _default_encoder.encode(obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 200, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 258, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type Series is not JSON serializable\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:561)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:94)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:75)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:514)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:385)\n",
      "\tat org.apache.spark.sql.execution.datasources.WriteFilesExec.$anonfun$doExecuteWrite$1(WriteFiles.scala:100)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:888)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:888)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "{'first_name': 'xxxx', 'last_name': 'xxxx', 'email': 'Unknown', 'mobile': 'Unknown', 'booker_type': 'Agent', 'city': 'Unknown', 'total_passengers': 4, 'unique': 1, 'first_date': '2017-01-25 10:00:33.733', 'last_date': '2018-06-28 08:59:58.937', 'booking_freq': {'jan': 3, 'feb': 0, 'mar': 0, 'apr': 0, 'may': 0, 'jun': 1, 'jul': 0, 'aug': 0, 'sep': 0, 'oct': 0, 'nov': 0, 'dec': 0}, 'seat_counts': {'Unknown': 2, '': 1, '26C': 1}, 'meals_count': {'None': 4}, 'destination_count': {'Unknown': 2, 'MNL': 1, 'ILO': 1}, 'channel_count': {'Direct': 4}, 'employee_count': {'No': 4}, 'baggage_count': {'None': 4}, 'gender_count': {'2': 4}, 'employee_related_count': {'No': 4}, 'insurance_count': {'None': 4}, 'origin_count': {'Unknown': 2, 'CEB': 1, 'MNL': 1}, 'travelby_count': {'Group': 2, 'Solo': 2}, 'isregistered_count': {'Yes': 4}, 'revenue': 15.02, 'timeline': [{'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"ILO\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2018-06-28 08:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.01\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"ILO\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2018-06-28 08:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.01\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"ILO\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2018-06-28 08:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.01\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"ILO\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2018-06-28 08:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.01\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"ILO\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2018-06-28 08:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.01\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"ILO\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2018-06-28 08:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.01\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"ILO\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2018-06-28 08:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.01\"\n",
      "]}]}\n",
      "23/04/16 21:05:02 WARN TaskSetManager: Lost task 2.0 in stage 46.0 (TID 177) (10.0.5.2 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_6942/4051122333.py\", line 168, in sum_ages\n",
      "  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/__init__.py\", line 231, in dumps\n",
      "    return _default_encoder.encode(obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 200, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 258, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type Series is not JSON serializable\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:561)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:94)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:75)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:514)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:385)\n",
      "\tat org.apache.spark.sql.execution.datasources.WriteFilesExec.$anonfun$doExecuteWrite$1(WriteFiles.scala:100)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:888)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:888)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n",
      "23/04/16 21:05:02 ERROR TaskSetManager: Task 2 in stage 46.0 failed 1 times; aborting job\n",
      "23/04/16 21:05:02 ERROR FileFormatWriter: Aborting job fbaf1e8b-062d-4a6d-bae0-a660b9331365.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 46.0 failed 1 times, most recent failure: Lost task 2.0 in stage 46.0 (TID 177) (10.0.5.2 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_6942/4051122333.py\", line 168, in sum_ages\n",
      "  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/__init__.py\", line 231, in dumps\n",
      "    return _default_encoder.encode(obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 200, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 258, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type Series is not JSON serializable\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:561)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:94)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:75)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:514)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:385)\n",
      "\tat org.apache.spark.sql.execution.datasources.WriteFilesExec.$anonfun$doExecuteWrite$1(WriteFiles.scala:100)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:888)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:888)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1206)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1206)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1206)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2984)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:971)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2263)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeWrite$4(FileFormatWriter.scala:307)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:271)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:304)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:190)\n",
      "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:190)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:354)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:382)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:354)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:789)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_6942/4051122333.py\", line 168, in sum_ages\n",
      "  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/__init__.py\", line 231, in dumps\n",
      "    return _default_encoder.encode(obj)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 200, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 258, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type Series is not JSON serializable\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:561)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:94)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:75)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:514)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:385)\n",
      "\tat org.apache.spark.sql.execution.datasources.WriteFilesExec.$anonfun$doExecuteWrite$1(WriteFiles.scala:100)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:888)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:888)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "23/04/16 21:05:02 WARN TaskSetManager: Lost task 7.0 in stage 46.0 (TID 182) (10.0.5.2 executor driver): TaskKilled (Stage cancelled)\n",
      "23/04/16 21:05:02 WARN TaskSetManager: Lost task 8.0 in stage 46.0 (TID 183) (10.0.5.2 executor driver): TaskKilled (Stage cancelled)\n",
      "23/04/16 21:05:02 WARN TaskSetManager: Lost task 1.0 in stage 46.0 (TID 176) (10.0.5.2 executor driver): TaskKilled (Stage cancelled)\n",
      "23/04/16 21:05:02 WARN TaskSetManager: Lost task 11.0 in stage 46.0 (TID 186) (10.0.5.2 executor driver): TaskKilled (Stage cancelled)\n",
      "23/04/16 21:05:02 WARN TaskSetManager: Lost task 5.0 in stage 46.0 (TID 180) (10.0.5.2 executor driver): TaskKilled (Stage cancelled)\n",
      "23/04/16 21:05:02 WARN TaskSetManager: Lost task 0.0 in stage 46.0 (TID 175) (10.0.5.2 executor driver): TaskKilled (Stage cancelled)\n",
      "23/04/16 21:05:02 WARN TaskSetManager: Lost task 3.0 in stage 46.0 (TID 178) (10.0.5.2 executor driver): TaskKilled (Stage cancelled)\n",
      "{'first_name': 'xxxx', 'last_name': 'xxxx', 'email': 'Unknown', 'mobile': 'Unknown', 'booker_type': 'Agent', 'city': 'Unknown', 'total_passengers': 1, 'unique': 1, 'first_date': '2021-11-09 04:00:22.41', 'last_date': '2021-11-09 04:00:22.41', 'booking_freq': {'jan': 0, 'feb': 0, 'mar': 0, 'apr': 0, 'may': 0, 'jun': 0, 'jul': 0, 'aug': 0, 'sep': 0, 'oct': 0, 'nov': 1, 'dec': 0}, 'seat_counts': {'Unknown': 1}, 'meals_count': {'None': 1}, 'destination_count': {'Unknown': 1}, 'channel_count': {'Direct': 1}, 'employee_count': {'No': 1}, 'baggage_count': {'None': 1}, 'gender_count': {'2': 1}, 'employee_related_count': {'No': 1}, 'insurance_count': {'None': 1}, 'origin_count': {'Unknown': 1}, 'travelby_count': {'Solo': 1}, 'isregistered_count': {'Yes': 1}, 'revenue': 0.0, 'timeline': [{'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2021-11-09 04:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.0\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2021-11-09 04:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.0\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2021-11-09 04:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.0\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2021-11-09 04:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.0\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2021-11-09 04:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.0\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2021-11-09 04:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.0\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2021-11-09 04:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP0.0\"\n",
      "]}]}\n",
      "{'first_name': 'xxxx', 'last_name': 'xxxx', 'email': 'tXXX@XXXX.com', 'mobile': 'Unknown', 'booker_type': 'Agent', 'city': 'Unknown', 'total_passengers': 2, 'unique': 1, 'first_date': '2020-07-07 09:04:44.843', 'last_date': '2020-07-08 02:05:49.303', 'booking_freq': {'jan': 0, 'feb': 0, 'mar': 0, 'apr': 0, 'may': 0, 'jun': 0, 'jul': 2, 'aug': 0, 'sep': 0, 'oct': 0, 'nov': 0, 'dec': 0}, 'seat_counts': {'Unknown': 1, '27C': 1}, 'meals_count': {'None': 2}, 'destination_count': {'Unknown': 1, 'MNL': 1}, 'channel_count': {'API': 1, 'Direct': 1}, 'employee_count': {'No': 2}, 'baggage_count': {'None': 2}, 'gender_count': {'1': 2}, 'employee_related_count': {'No': 2}, 'insurance_count': {'None': 2}, 'origin_count': {'Unknown': 1, 'BXU': 1}, 'travelby_count': {'Group': 2}, 'isregistered_count': {'Yes': 2}, 'revenue': 779.88, 'timeline': [{'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"BXU\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2020-07-08 02:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP779.88\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"BXU\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2020-07-08 02:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP779.88\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"BXU\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2020-07-08 02:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP779.88\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"BXU\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2020-07-08 02:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP779.88\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"BXU\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2020-07-08 02:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP779.88\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"BXU\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2020-07-08 02:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP779.88\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"BXU\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"Direct\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2020-07-08 02:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP779.88\"\n",
      "]}]}\n",
      "{'first_name': 'xxxx', 'last_name': 'xxxx', 'email': 'Unknown', 'mobile': 'Unknown', 'booker_type': 'Agent', 'city': 'Unknown', 'total_passengers': 1, 'unique': 1, 'first_date': '2018-06-28 09:33:11.827', 'last_date': '2018-06-28 09:33:11.827', 'booking_freq': {'jan': 0, 'feb': 0, 'mar': 0, 'apr': 0, 'may': 0, 'jun': 1, 'jul': 0, 'aug': 0, 'sep': 0, 'oct': 0, 'nov': 0, 'dec': 0}, 'seat_counts': {'Unknown': 1}, 'meals_count': {'None': 1}, 'destination_count': {'Unknown': 1}, 'channel_count': {'API': 1}, 'employee_count': {'No': 1}, 'baggage_count': {'None': 1}, 'gender_count': {'2': 1}, 'employee_related_count': {'No': 1}, 'insurance_count': {'None': 1}, 'origin_count': {'Unknown': 1}, 'travelby_count': {'Group': 1}, 'isregistered_count': {'Yes': 1}, 'revenue': 7220.0, 'timeline': [{'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2018-06-28 09:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP7220.0\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2018-06-28 09:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP7220.0\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2018-06-28 09:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP7220.0\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2018-06-28 09:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP7220.0\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2018-06-28 09:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP7220.0\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2018-06-28 09:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP7220.0\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"Unknown\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2018-06-28 09:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP7220.0\"\n",
      "]}]}\n",
      "23/04/16 21:05:03 WARN TaskSetManager: Lost task 6.0 in stage 46.0 (TID 181) (10.0.5.2 executor driver): TaskKilled (Stage cancelled)\n",
      "23/04/16 21:05:03 WARN TaskSetManager: Lost task 4.0 in stage 46.0 (TID 179) (10.0.5.2 executor driver): TaskKilled (Stage cancelled)\n",
      "{'first_name': 'xxxx', 'last_name': 'xxxx', 'email': 'mXXX@XXXX.com', 'mobile': 'Unknown', 'booker_type': 'Agent', 'city': 'Unknown', 'total_passengers': 1, 'unique': 1, 'first_date': '2022-02-23 05:26:34.483', 'last_date': '2022-02-23 05:26:34.483', 'booking_freq': {'jan': 0, 'feb': 1, 'mar': 0, 'apr': 0, 'may': 0, 'jun': 0, 'jul': 0, 'aug': 0, 'sep': 0, 'oct': 0, 'nov': 0, 'dec': 0}, 'seat_counts': {'2A_26A': 1}, 'meals_count': {'None': 1}, 'destination_count': {'MPH_MNL': 1}, 'channel_count': {'API': 1}, 'employee_count': {'No': 1}, 'baggage_count': {'Checked Baggage Allowance - 20 Kilos': 1}, 'gender_count': {'1': 1}, 'employee_related_count': {'No': 1}, 'insurance_count': {'None': 1}, 'origin_count': {'MNL': 1}, 'travelby_count': {'Solo': 1}, 'isregistered_count': {'Yes': 1}, 'revenue': 16482.52, 'timeline': [{'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"MPH_MNL\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"Checked Baggag…\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2022-02-23 05:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP16482.52\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"MPH_MNL\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"Checked Baggag…\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2022-02-23 05:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP16482.52\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"MPH_MNL\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"Checked Baggag…\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2022-02-23 05:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP16482.52\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"MPH_MNL\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"Checked Baggag…\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2022-02-23 05:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP16482.52\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"MPH_MNL\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"Checked Baggag…\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2022-02-23 05:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP16482.52\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"MPH_MNL\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"Checked Baggag…\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2022-02-23 05:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP16482.52\"\n",
      "]}, {'origin': shape: (1,)\n",
      "Series: 'origin' [str]\n",
      "[\n",
      "\t\"MNL\"\n",
      "], 'destination': shape: (1,)\n",
      "Series: 'destination' [str]\n",
      "[\n",
      "\t\"MPH_MNL\"\n",
      "], 'channel': shape: (1,)\n",
      "Series: 'channel' [str]\n",
      "[\n",
      "\t\"API\"\n",
      "], 'baggage': shape: (1,)\n",
      "Series: 'baggage' [str]\n",
      "[\n",
      "\t\"Checked Baggag…\n",
      "], 'meals': shape: (1,)\n",
      "Series: 'meals' [str]\n",
      "[\n",
      "\t\"None\"\n",
      "], 'booking_date': shape: (1,)\n",
      "Series: 'booking_date' [str]\n",
      "[\n",
      "\t\"2022-02-23 05:…\n",
      "], 'revenue': shape: (1,)\n",
      "Series: 'booking_currency' [str]\n",
      "[\n",
      "\t\"PHP16482.52\"\n",
      "]}]}\n",
      "23/04/16 21:05:03 WARN TaskSetManager: Lost task 10.0 in stage 46.0 (TID 185) (10.0.5.2 executor driver): TaskKilled (Stage cancelled)\n"
     ]
    },
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/tmp/ipykernel_6942/4051122333.py\", line 168, in sum_ages\n  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/__init__.py\", line 231, in dumps\n    return _default_encoder.encode(obj)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 200, in encode\n    chunks = self.iterencode(o, _one_shot=True)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 258, in iterencode\n    return _iterencode(o, 0)\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 180, in default\n    raise TypeError(f'Object of type {o.__class__.__name__} '\nTypeError: Object of type Series is not JSON serializable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 183\u001b[0m\n\u001b[1;32m    171\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mfillna(\u001b[39m\"\u001b[39m\u001b[39mUnknown\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    173\u001b[0m result \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mgroupBy((\u001b[39m\"\u001b[39m\u001b[39mPersonID\u001b[39m\u001b[39m\"\u001b[39m))\u001b[39m.\u001b[39magg(\n\u001b[1;32m    174\u001b[0m     mode_udf(F\u001b[39m.\u001b[39mcollect_list(\u001b[39m\"\u001b[39m\u001b[39mBookerFirstName\u001b[39m\u001b[39m\"\u001b[39m))\u001b[39m.\u001b[39malias(\u001b[39m\"\u001b[39m\u001b[39mFirst_Name\u001b[39m\u001b[39m\"\u001b[39m),mode_udf(F\u001b[39m.\u001b[39mcollect_list(\u001b[39m\"\u001b[39m\u001b[39mBookerLastName\u001b[39m\u001b[39m\"\u001b[39m))\u001b[39m.\u001b[39malias(\u001b[39m\"\u001b[39m\u001b[39mLast_Name\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    175\u001b[0m mode_udf(F\u001b[39m.\u001b[39mcollect_list(\u001b[39m\"\u001b[39m\u001b[39mBookerMobile\u001b[39m\u001b[39m\"\u001b[39m))\u001b[39m.\u001b[39malias(\u001b[39m\"\u001b[39m\u001b[39mMobile\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m F\u001b[39m.\u001b[39mcollect_list(\u001b[39m\"\u001b[39m\u001b[39mTravelBaggage\u001b[39m\u001b[39m\"\u001b[39m),F\u001b[39m.\u001b[39mcollect_list(\u001b[39m\"\u001b[39m\u001b[39mGender\u001b[39m\u001b[39m\"\u001b[39m),F\u001b[39m.\u001b[39mcollect_list(\u001b[39m\"\u001b[39m\u001b[39mIsEmployeeDependent\u001b[39m\u001b[39m\"\u001b[39m),F\u001b[39m.\u001b[39mcollect_list(\u001b[39m\"\u001b[39m\u001b[39mTravelInsurance\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    182\u001b[0m F\u001b[39m.\u001b[39mcollect_list(\u001b[39m\"\u001b[39m\u001b[39mTravelOrigin\u001b[39m\u001b[39m\"\u001b[39m),F\u001b[39m.\u001b[39mcollect_list(\u001b[39m\"\u001b[39m\u001b[39mTravelSoloOrGroup\u001b[39m\u001b[39m\"\u001b[39m), F\u001b[39m.\u001b[39mcollect_list(\u001b[39m\"\u001b[39m\u001b[39mDateOfBirth\u001b[39m\u001b[39m\"\u001b[39m),F\u001b[39m.\u001b[39mcollect_list(\u001b[39m\"\u001b[39m\u001b[39mIsRegistered\u001b[39m\u001b[39m\"\u001b[39m),F\u001b[39m.\u001b[39mcollect_list(\u001b[39m\"\u001b[39m\u001b[39mBookingCurrency\u001b[39m\u001b[39m\"\u001b[39m),F\u001b[39m.\u001b[39mcollect_list(\u001b[39m\"\u001b[39m\u001b[39mpassenger_hash\u001b[39m\u001b[39m\"\u001b[39m))\u001b[39m.\u001b[39malias(\u001b[39m\"\u001b[39m\u001b[39mDetails\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m--> 183\u001b[0m result\u001b[39m.\u001b[39;49mwrite\u001b[39m.\u001b[39;49mparquet(\u001b[39m\"\u001b[39;49m\u001b[39mperson_profiles.parquet\u001b[39;49m\u001b[39m\"\u001b[39;49m, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39moverwrite\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/pyspark/sql/readwriter.py:1656\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m   1654\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpartitionBy(partitionBy)\n\u001b[1;32m   1655\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_opts(compression\u001b[39m=\u001b[39mcompression)\n\u001b[0;32m-> 1656\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jwrite\u001b[39m.\u001b[39;49mparquet(path)\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/tmp/ipykernel_6942/4051122333.py\", line 168, in sum_ages\n  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/__init__.py\", line 231, in dumps\n    return _default_encoder.encode(obj)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 200, in encode\n    chunks = self.iterencode(o, _one_shot=True)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 258, in iterencode\n    return _iterencode(o, 0)\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/json/encoder.py\", line 180, in default\n    raise TypeError(f'Object of type {o.__class__.__name__} '\nTypeError: Object of type Series is not JSON serializable\n"
     ]
    }
   ],
   "source": [
    "@udf()\n",
    "def sum_ages(first_name,last_name, email,mobile, revenue,booker_type,city,total_passengers,bookerid,\n",
    " booking_date,travelseat,meals,destination,channel,isemployee,baggage,gender,employee_related,insurance,\n",
    " origin,travelby,dob,isregistered, bookingcurrency, passenger_hash):\n",
    "    # build a polars dataframe from the column arrays\n",
    "    df = pl.DataFrame({\n",
    "        'first_name': first_name,\n",
    "        'last_name': last_name,\n",
    "        'email': email,\n",
    "        'mobile': mobile,\n",
    "        'revenue': revenue,\n",
    "        'booker_type': booker_type,\n",
    "        'city': city,\n",
    "        'total_passengers': total_passengers,\n",
    "        'bookerid': bookerid,\n",
    "        'booking_date': booking_date,\n",
    "        'travelseat': travelseat,\n",
    "        'meals': meals,\n",
    "        'destination': destination,\n",
    "        'channel': channel,\n",
    "        'isemployee': isemployee,\n",
    "        'baggage': baggage,\n",
    "        'gender': gender,\n",
    "        'employee_related': employee_related,\n",
    "        'insurance': insurance,\n",
    "        'origin': origin,\n",
    "        'travelby': travelby,\n",
    "        'dob': dob,\n",
    "        'isregistered': isregistered,\n",
    "        'booking_currency': bookingcurrency,\n",
    "        'passenger_hash': passenger_hash\n",
    "    })\n",
    "    # sort on booking date\n",
    "    df = df.sort('booking_date')\n",
    "    first_date = df['booking_date'].min()\n",
    "    last_date = df['booking_date'].max()\n",
    "    exchange_rates= {'THB': 0.657845, 'AED': 13.203984, 'MYR': 7.624044, 'EUR': 0.011741, 'OMR': 0.001127, 'KWD': 0.003423, 'VND': 254.181015, 'USD': 0.019467, 'AUD': 0.025128, 'CNY': 0.126146, 'PHP': 1.0, 'KRW': 22.734294, 'JPY': 2.180405, 'HKD': 0.151516, 'TWD': 0.539236, 'QAR': 0.071024, 'MOP': 0.156013, 'IDR': 278.384131, 'SAR': 0.073001, 'INR': 1.427856, 'BHD': 0.007356, 'SGD': 0.026176, 'BND': 0.026101}\n",
    "    def transform_revenue(booking_currency, revenue):\n",
    "        # booking_currency = row.get('bookingcurrency')\n",
    "        rev = []\n",
    "        for idx, each_booking_currency in enumerate(booking_currency): \n",
    "            if each_booking_currency in exchange_rates:\n",
    "                exchange_rate = exchange_rates[each_booking_currency]\n",
    "                transformed_revenue = revenue[idx] * exchange_rate\n",
    "                rev.append(transformed_revenue)\n",
    "            else:\n",
    "                rev.append(revenue[idx])\n",
    "        return pl.Series('revenue', rev) \n",
    "    df = df.with_columns([\n",
    "        transform_revenue(df['booking_currency'], df['revenue'])\n",
    "    ])\n",
    "    # df['revenue'] = df.apply(transform_revenue)\n",
    "    # iterate over booking_date\n",
    "    booking_freq = {}\n",
    "    # for date in df['booking_date'].to_list():\n",
    "    #     # date is %d-%m-%Y\n",
    "    #     month = date.split('-')[1]\n",
    "    #     try:\n",
    "    #         month_name = calendar.month_name[int(month)]\n",
    "    #     except:\n",
    "    #         month_name = \"Unknown\"\n",
    "    #     if month in booking_freq:            \n",
    "    #         booking_freq[month_name] += 1\n",
    "    #     else:\n",
    "    #         booking_freq[month] = 1\n",
    "    booking_freq = {\n",
    "        'jan': 0,\n",
    "        'feb': 0,\n",
    "        'mar': 0,\n",
    "        'apr': 0,\n",
    "        'may': 0,\n",
    "        'jun': 0,\n",
    "        'jul': 0,\n",
    "        'aug': 0,\n",
    "        'sep': 0,\n",
    "        'oct': 0,\n",
    "        'nov': 0,\n",
    "        'dec': 0,\n",
    "    }\n",
    "    dates = df['booking_date'].to_list()\n",
    "    for date in dates:\n",
    "        if date.split('-')[1] == '01':\n",
    "            booking_freq['jan'] += 1\n",
    "        elif date.split('-')[1] == '02':\n",
    "            booking_freq['feb'] += 1\n",
    "        elif date.split('-')[1] == '03':\n",
    "            booking_freq['mar'] += 1\n",
    "        elif date.split('-')[1] == '04':\n",
    "            booking_freq['apr'] += 1\n",
    "        elif date.split('-')[1] == '05':\n",
    "            booking_freq['may'] += 1\n",
    "        elif date.split('-')[1] == '06':\n",
    "            booking_freq['jun'] += 1\n",
    "        elif date.split('-')[1] == '07':\n",
    "            booking_freq['jul'] += 1\n",
    "        elif date.split('-')[1] == '08':\n",
    "            booking_freq['aug'] += 1\n",
    "        elif date.split('-')[1] == '09':\n",
    "            booking_freq['sep'] += 1\n",
    "        elif date.split('-')[1] == '10':\n",
    "            booking_freq['oct'] += 1\n",
    "        elif date.split('-')[1] == '11':\n",
    "            booking_freq['nov'] += 1\n",
    "        elif date.split('-')[1] == '12':\n",
    "            booking_freq['dec'] += 1\n",
    "    timeline = []\n",
    "    # loop on last 7 records in reverse order\n",
    "    for i in range(1,8):\n",
    "        row = df.tail(1)\n",
    "        timeline.append({\n",
    "            'origin': row['origin'],\n",
    "            'destination': row['destination'],\n",
    "            'channel': row['channel'],\n",
    "            'baggage': row['baggage'],\n",
    "            'meals': row['meals'],\n",
    "            'booking_date': row['booking_date'],\n",
    "            'revenue': row['booking_currency'] + row['revenue'],\n",
    "        }\n",
    "    )\n",
    "    dobss = []\n",
    "    for db in dob:\n",
    "        if db != 'Unknown':\n",
    "            dobss.append(calculate_age((db)))\n",
    "        else:\n",
    "            dobss.append('Unknown')\n",
    "    \n",
    "    age_groups = range(1, 111, 10)\n",
    "\n",
    "    age_group_counts = {f'{i}-{i+9}': 0 for i in age_groups}\n",
    "    age_group_counts['unknown'] = 0\n",
    "    for age in dobss:\n",
    "        if age == 'Unknown':\n",
    "            age_group_counts['unknown'] += 1\n",
    "        for i in age_groups:\n",
    "            if age in range(i, i+10):\n",
    "                age_group_counts[f'{i}-{i+9}'] += 1\n",
    "    # get most frequent first name\n",
    "    def mode(column_arr):\n",
    "        return statistics.mode(column_arr)\n",
    "    temp = {\n",
    "        \"first_name\" : mode(first_name),\n",
    "        \"last_name\" : mode(last_name),\n",
    "        \"email\" : mode(email),\n",
    "        \"mobile\" : mode(mobile),\n",
    "        \"booker_type\" : mode(booker_type),\n",
    "        \"city\" : mode(city),\n",
    "        \"total_passengers\" : df.shape[0],\n",
    "        \"unique\" : df['passenger_hash'].unique().shape[0],\n",
    "        \"first_date\" : first_date,\n",
    "        \"last_date\" : last_date,\n",
    "        \"booking_freq\" : booking_freq,\n",
    "        \"seat_counts\" : dict(Counter(travelseat)),\n",
    "        \"meals_count\" : dict(Counter(meals)),\n",
    "        \"destination_count\" : dict(Counter(destination)),\n",
    "        \"channel_count\" : dict(Counter(channel)),\n",
    "        \"employee_count\" : dict(Counter(isemployee)),\n",
    "        \"baggage_count\" : dict(Counter(baggage)),\n",
    "        \"gender_count\" : dict(Counter(gender)),\n",
    "        \"employee_related_count\" : dict(Counter(employee_related)),\n",
    "        \"insurance_count\" : dict(Counter(insurance)),\n",
    "        \"origin_count\" : dict(Counter(origin)),\n",
    "        \"travelby_count\" : dict(Counter(travelby)),\n",
    "        \"isregistered_count\" : dict(Counter(isregistered)),\n",
    "        \"revenue\" : df['revenue'].sum(),\n",
    "        \"timeline\" : timeline,\n",
    "    }\n",
    "    print(temp)\n",
    "    return json.dumps(temp)\n",
    "\n",
    "# pyspark fill null values with Unknown\n",
    "df = df.fillna(\"Unknown\")\n",
    "\n",
    "result = df.groupBy((\"PersonID\")).agg(\n",
    "    mode_udf(F.collect_list(\"BookerFirstName\")).alias(\"First_Name\"),mode_udf(F.collect_list(\"BookerLastName\")).alias(\"Last_Name\"),\n",
    "mode_udf(F.collect_list(\"BookerMobile\")).alias(\"Mobile\"),\n",
    "mode_udf(F.collect_list(\"BookerEmailAddress\")).alias(\"Email\")\n",
    ",sum_ages(F.collect_list(\"BookerFirstName\"),F.collect_list(\"BookerLastName\"),F.collect_list(\"BookerEmailAddress\"),\n",
    "F.collect_list(\"BookerMobile\"),F.collect_list(\"Revenue\"),F.collect_list(\"BookerType\"),F.collect_list(\"BookerCity\"),\n",
    "F.collect_list(\"PassengerID\"),F.collect_list(\"PersonID\"),F.collect_list(\"BookingDate\"),F.collect_list(\"TravelSeat\"),\n",
    "F.collect_list(\"TravelMeals\"),F.collect_list(\"TravelDestination\"),F.collect_list(\"BookingChannel\"),F.collect_list(\"IsEmployee\"),\n",
    "F.collect_list(\"TravelBaggage\"),F.collect_list(\"Gender\"),F.collect_list(\"IsEmployeeDependent\"),F.collect_list(\"TravelInsurance\"),\n",
    "F.collect_list(\"TravelOrigin\"),F.collect_list(\"TravelSoloOrGroup\"), F.collect_list(\"DateOfBirth\"),F.collect_list(\"IsRegistered\"),F.collect_list(\"BookingCurrency\"),F.collect_list(\"passenger_hash\")).alias(\"Details\"))\n",
    "result.write.parquet(\"person_profiles.parquet\", mode=\"overwrite\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Made some modifications to previous code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, -1)\n",
      "(2, 5)\n",
      "(3, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column_0</th><th>column_1</th></tr><tr><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>2</td><td>-3</td></tr><tr><td>4</td><td>15</td></tr><tr><td>6</td><td>24</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌──────────┬──────────┐\n",
       "│ column_0 ┆ column_1 │\n",
       "│ ---      ┆ ---      │\n",
       "│ i64      ┆ i64      │\n",
       "╞══════════╪══════════╡\n",
       "│ 2        ┆ -3       │\n",
       "│ 4        ┆ 15       │\n",
       "│ 6        ┆ 24       │\n",
       "└──────────┴──────────┘"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import udf, col, size, collect_set, collect_list\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from collections import Counter\n",
    "from pyspark.sql.functions import col, collect_set, struct,count\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType\n",
    "from datetime import date\n",
    "import statistics\n",
    "import json\n",
    "import polars as pl\n",
    "spark = SparkSession.builder.appName('customer360.ai').getOrCreate()\n",
    "\n",
    "\n",
    "df = spark.read.parquet(\"cdp_profiles.parquet\")\n",
    "\n",
    "\n",
    "def calculate_age(born_str):\n",
    "    born = date.fromisoformat(born_str)\n",
    "    today = date.today()\n",
    "    return today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n",
    "\n",
    "@udf \n",
    "def abs(column_arr):\n",
    "    return statistics.mode(column_arr)\n",
    "\n",
    "@udf()\n",
    "def sum_ages(first_name,last_name, email,mobile, revenue,booker_type,city,total_passengers,bookerid,\n",
    " booking_date,travelseat,meals,destination,channel,isemployee,baggage,gender,employee_related,insurance,\n",
    " origin,travelby,dob,isregistered,bookingcurrency, passenger_hash):\n",
    "    # build a polars dataframe from the column arrays\n",
    "    df = pl.DataFrame({\n",
    "        'first_name': first_name,\n",
    "        'last_name': last_name,\n",
    "        'email': email,\n",
    "        'mobile': mobile,\n",
    "        'revenue': revenue,\n",
    "        'booker_type': booker_type,\n",
    "        'city': city,\n",
    "        'total_passengers': total_passengers,\n",
    "        'bookerid': bookerid,\n",
    "        'booking_date': booking_date,\n",
    "        'travelseat': travelseat,\n",
    "        'meals': meals,\n",
    "        'destination': destination,\n",
    "        'channel': channel,\n",
    "        'isemployee': isemployee,\n",
    "        'baggage': baggage,\n",
    "        'gender': gender,\n",
    "        'employee_related': employee_related,\n",
    "        'insurance': insurance,\n",
    "        'origin': origin,\n",
    "        'travelby': travelby,\n",
    "        'dob': dob,\n",
    "        'isregistered': isregistered\n",
    "    })\n",
    "    # sort on booking date\n",
    "    df = df.sort('booking_date')\n",
    "\n",
    "    first_date = df['booking_date'].min()\n",
    "    last_date = df['booking_date'].max()\n",
    "    dicts = {\n",
    "        'jan': 0,\n",
    "        'feb': 0,\n",
    "        'mar': 0,\n",
    "        'apr': 0,\n",
    "        'may': 0,\n",
    "        'jun': 0,\n",
    "        'jul': 0,\n",
    "        'aug': 0,\n",
    "        'sep': 0,\n",
    "        'oct': 0,\n",
    "        'nov': 0,\n",
    "        'dec': 0,\n",
    "    }\n",
    "    dates = df['booking_date'].to_list()\n",
    "    for date in dates:\n",
    "        if date.split('-')[1] == '01':\n",
    "            dicts['jan'] += 1\n",
    "        elif date.split('-')[1] == '02':\n",
    "            dicts['feb'] += 1\n",
    "        elif date.split('-')[1] == '03':\n",
    "            dicts['mar'] += 1\n",
    "        elif date.split('-')[1] == '04':\n",
    "            dicts['apr'] += 1\n",
    "        elif date.split('-')[1] == '05':\n",
    "            dicts['may'] += 1\n",
    "        elif date.split('-')[1] == '06':\n",
    "            dicts['jun'] += 1\n",
    "        elif date.split('-')[1] == '07':\n",
    "            dicts['jul'] += 1\n",
    "        elif date.split('-')[1] == '08':\n",
    "            dicts['aug'] += 1\n",
    "        elif date.split('-')[1] == '09':\n",
    "            dicts['sep'] += 1\n",
    "        elif date.split('-')[1] == '10':\n",
    "            dicts['oct'] += 1\n",
    "        elif date.split('-')[1] == '11':\n",
    "            dicts['nov'] += 1\n",
    "        elif date.split('-')[1] == '12':\n",
    "            dicts['dec'] += 1\n",
    "\n",
    "    booking_dates = []\n",
    "\n",
    "    if(len(dates)<6):\n",
    "        booking_dates = dates\n",
    "    else:\n",
    "        booking_dates = dates[-6:]\n",
    "    \n",
    "    timeline = {}\n",
    "    for i in range(len(booking_dates)):\n",
    "        index = dates.index(booking_dates[i])\n",
    "        timeline[i+1] = {\n",
    "            'origin': origin[index],\n",
    "            'destination': destination[index],\n",
    "            'channel':channel[index],\n",
    "            'baggage':baggage[index],\n",
    "            'meals':meals[index],\n",
    "            'booking_date':booking_date[index],\n",
    "            'revenue':revenue[index]\n",
    "        }\n",
    "\n",
    "    dobss = []\n",
    "    for db in dob:\n",
    "        if db != 'Unknown':\n",
    "            dobss.append(calculate_age((db)))\n",
    "        else:\n",
    "            dobss.append('Unknown')\n",
    "    \n",
    "    age_groups = range(1, 111, 10)\n",
    "\n",
    "    age_group_counts = {f'{i}-{i+9}': 0 for i in age_groups}\n",
    "    age_group_counts['unknown'] = 0\n",
    "    for age in dobss:\n",
    "        if age == 'Unknown':\n",
    "            age_group_counts['unknown'] += 1\n",
    "        for i in age_groups:\n",
    "            if age in range(i, i+10):\n",
    "                age_group_counts[f'{i}-{i+9}'] += 1\n",
    "\n",
    "\n",
    "    seat_counts = dict(Counter(travelseat))\n",
    "    meals_count = dict(Counter(meals))\n",
    "    destination_count = dict(Counter(destination))\n",
    "    channel_count = dict(Counter(channel))\n",
    "    employee_count = dict(Counter(isemployee))\n",
    "    baggage_count = dict(Counter(baggage))\n",
    "    gender_count = dict(Counter(gender))\n",
    "    employee_related_count = dict(Counter(employee_related))\n",
    "    insurance_count = dict(Counter(insurance))\n",
    "    origin_count = dict(Counter(origin))\n",
    "    travelby_count = dict(Counter(travelby))\n",
    "    isregistered_count = dict(Counter(isregistered))\n",
    "        \n",
    "    temp = {'first_name': first_name[0],'last_name' :last_name[0],'email' :email[0],'mobile' :mobile[0],'revenue': sum(revenue),\n",
    "    'booker_type':booker_type[0],'city':city[0],'total_passengers':len(total_passengers),\n",
    "    'bookerid':bookerid[0], 'first_date': first_date, 'last_date': last_date,'dicts':dicts,'travelseat':seat_counts,\n",
    "    'meals':meals_count,'destination':destination_count,'channel':channel_count,'isemployee':employee_count,\n",
    "    'baggage':baggage_count,'gender':gender_count,'employee_related':employee_related_count,'insurance':insurance_count,\n",
    "    'origin':origin_count,'travelby':travelby_count, 'dob': age_group_counts,'isregistered':isregistered_count,'timeline':timeline}\n",
    "    details = json.dumps(temp)\n",
    "    return details\n",
    "result = df.groupBy((\"PersonID\")).agg(\n",
    "    abs(F.collect_list(\"BookerFirstName\")).alias(\"First_Name\"),abs(F.collect_list(\"BookerLastName\")).alias(\"Last_Name\"),\n",
    "abs(F.collect_list(\"BookerMobile\")).alias(\"Mobile\"),\n",
    "abs(F.collect_list(\"BookerEmailAddress\")).alias(\"Email\")\n",
    ",sum_ages(F.collect_list(\"BookerFirstName\"),F.collect_list(\"BookerLastName\"),F.collect_list(\"BookerEmailAddress\"),\n",
    "F.collect_list(\"BookerMobile\"),F.collect_list(\"Revenue\"),F.collect_list(\"BookerType\"),F.collect_list(\"BookerCity\"),\n",
    "F.collect_list(\"PassengerID\"),F.collect_list(\"PersonID\"),F.collect_list(\"BookingDate\"),F.collect_list(\"TravelSeat\"),\n",
    "F.collect_list(\"TravelMeals\"),F.collect_list(\"TravelDestination\"),F.collect_list(\"BookingChannel\"),F.collect_list(\"IsEmployee\"),\n",
    "F.collect_list(\"TravelBaggage\"),F.collect_list(\"Gender\"),F.collect_list(\"IsEmployeeDependent\"),F.collect_list(\"TravelInsurance\"),\n",
    "F.collect_list(\"TravelOrigin\"),F.collect_list(\"TravelSoloOrGroup\"), F.collect_list(\"DateOfBirth\"),F.collect_list(\"IsRegistered\"),F.collect_list(\"BookingCurrency\"),F.collect_list(\"passenger_hash\")).alias(\"Details\"))\n",
    "# result.show(truncate=False)\n",
    "\n",
    "# save the result to a parquet file\n",
    "result.write.parquet(\"person_profiles.parquet\", mode=\"overwrite\")\n",
    "\n",
    "\n",
    "@udf()\n",
    "def passenger_queries(first_name,middle_name,last_name,\n",
    "dob,gender,phone,email,city,\n",
    "state,zipcode,nation,key,booking_date,revenue,\n",
    "isregistered,passengerid,baggage,travelby,channel,\n",
    "insurance,origin,meals,travelseat,destination):\n",
    "\n",
    "    name = first_name[0] + \" \" + middle_name[0] + \" \"+last_name[0]\n",
    "    bookings_counts = dict(Counter(passengerid))\n",
    "    dates =[x.split(\" \")[0] for x in booking_date]\n",
    "    # sort the dates and get the first and last date\n",
    "    first_date = sorted(dates)[0]\n",
    "    last_date = sorted(dates)[-1]\n",
    "    total_revenue = sum(revenue)\n",
    "    isregistered_count = dict(Counter(isregistered))\n",
    "    dicts = {\n",
    "        'jan': 0,\n",
    "        'feb': 0,\n",
    "        'mar': 0,\n",
    "        'apr': 0,\n",
    "        'may': 0,\n",
    "        'jun': 0,\n",
    "        'jul': 0,\n",
    "        'aug': 0,\n",
    "        'sep': 0,\n",
    "        'oct': 0,\n",
    "        'nov': 0,\n",
    "        'dec': 0,\n",
    "    }\n",
    "    for date in dates:\n",
    "        if date.split('-')[1] == '01':\n",
    "            dicts['jan'] += 1\n",
    "        elif date.split('-')[1] == '02':\n",
    "            dicts['feb'] += 1\n",
    "        elif date.split('-')[1] == '03':\n",
    "            dicts['mar'] += 1\n",
    "        elif date.split('-')[1] == '04':\n",
    "            dicts['apr'] += 1\n",
    "        elif date.split('-')[1] == '05':\n",
    "            dicts['may'] += 1\n",
    "        elif date.split('-')[1] == '06':\n",
    "            dicts['jun'] += 1\n",
    "        elif date.split('-')[1] == '07':\n",
    "            dicts['jul'] += 1\n",
    "        elif date.split('-')[1] == '08':\n",
    "            dicts['aug'] += 1\n",
    "        elif date.split('-')[1] == '09':\n",
    "            dicts['sep'] += 1\n",
    "        elif date.split('-')[1] == '10':\n",
    "            dicts['oct'] += 1\n",
    "        elif date.split('-')[1] == '11':\n",
    "            dicts['nov'] += 1\n",
    "        elif date.split('-')[1] == '12':\n",
    "            dicts['dec'] += 1\n",
    "\n",
    "    baggage_count = dict(Counter(baggage))\n",
    "    travelby_count = dict(Counter(travelby))\n",
    "    channel_count = dict(Counter(channel))\n",
    "    insurance_count = dict(Counter(insurance))\n",
    "    origin_count = dict(Counter(origin))\n",
    "    meals_count = dict(Counter(meals))\n",
    "    seat_counts = dict(Counter(travelseat))\n",
    "    destination_counts = dict(Counter(destination))\n",
    "    booking_dates = []\n",
    "\n",
    "    if(len(dates)<6):\n",
    "        booking_dates = dates\n",
    "    else:\n",
    "        booking_dates = dates[-6:]\n",
    "    \n",
    "    timeline = {}\n",
    "    for i in range(len(booking_dates)):\n",
    "        index = dates.index(booking_dates[i])\n",
    "        timeline[i+1] = {\n",
    "            'origin': origin[index],\n",
    "            'destination': destination[index],\n",
    "            'channel':channel[index],\n",
    "            'baggage':baggage[index],\n",
    "            'meals':meals[index],\n",
    "            'booking_date':booking_date[index],\n",
    "            'revenue':revenue[index]\n",
    "        }\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    temp_pass = {'fullname': name,'dob':dob,'gender':gender,'phone':phone,'email':email,'city':city,'state':state,\n",
    "    'zipcode':zipcode,'nation':nation,'key':key,'first_date': first_date, 'last_date': last_date,\n",
    "    'revenue':total_revenue,'isregistered':isregistered_count,'passengerid':passengerid,'dicts':dicts,'baggage':baggage_count,\n",
    "    'travelby':travelby_count,'channel':channel_count,'insurance':insurance_count,'origin':origin_count,'meals':meals_count,'travelseat':seat_counts,\n",
    "    'destination':destination_counts,'timeline':timeline}\n",
    "    return json.dumps(temp_pass)\n",
    "\n",
    "result_passenger = df.groupBy(\"PassengerID\").agg(passenger_queries(F.collect_list(\"FirstName\")\n",
    ",F.collect_list(\"MiddleName\"),F.collect_list(\"LastName\"),F.collect_list(\"DateOfBirth\"),\n",
    "F.collect_list(\"Gender\"),F.collect_list(\"Phone\"),F.collect_list(\"EmailAddress\"),F.collect_list(\"City\"),\n",
    "F.collect_list(\"State\"),F.collect_list(\"ZipCode\"),F.collect_list(\"Nationality\"),F.collect_list(\"ProvisionalPrimaryKey\"),\n",
    "F.collect_list(\"BookingDate\"),F.collect_list('Revenue'),F.collect_list('IsRegistered'),F.collect_list('PassengerID'),\n",
    "F.collect_list(\"TravelBaggage\"),F.collect_list(\"TravelSoloOrGroup\"),F.collect_list(\"BookingChannel\"),F.collect_list(\"TravelInsurance\"),\n",
    "F.collect_list(\"TravelOrigin\"),F.collect_list(\"TravelMeals\"),F.collect_list(\"TravelSeat\"),F.collect_list(\"TravelDestination\")).alias(\"results\"))\n",
    "\n",
    "# result_passenger.show(truncate=False)\n",
    "result_passenger.write.parquet(\"passenger_profiles.parquet\", mode=\"overwrite\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
